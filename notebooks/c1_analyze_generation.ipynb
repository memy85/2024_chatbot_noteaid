{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24ec60cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import *\n",
    "\n",
    "config = load_config()\n",
    "PROJECT_PATH = config.project_path\n",
    "DATA_PATH = PROJECT_PATH.joinpath(\"data/processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c7803e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4o_mini = pd.read_pickle(DATA_PATH.joinpath('gpt-4o-mini_c1.pkl'))\n",
    "llama32 = pd.read_pickle(DATA_PATH.joinpath('llama-3.2-3B_c1.pkl'))\n",
    "llama32_lora = pd.read_pickle(DATA_PATH.joinpath('llama-3.2-3B-lora_c1.pkl'))\n",
    "llama32_sft = pd.read_pickle(DATA_PATH.joinpath('llama-3.2-3B-sft_c1.pkl'))\n",
    "llama32_lora_ppo = pd.read_pickle(DATA_PATH.joinpath('llama-3.2-3B-lora-ppo_c1.pkl'))\n",
    "llama32_lora_grpo = pd.read_pickle(DATA_PATH.joinpath('llama-3.2-3B-lora-grpo_c1.pkl'))\n",
    "\n",
    "model_names = ['gpt-4o-mini','llama3.2-3B', 'llama3.2-3B-sft', 'llama3.2-3B-lora', 'llama3.2-3B-lora-ppo', 'llama3.2-3B-lora-grpo']\n",
    "results = [gpt_4o_mini, llama32, llama32_sft, llama32_lora, llama32_lora_ppo, llama32_lora_grpo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc213644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_bleu(model_data) :\n",
    "    return round(model_data['bleu']['bleu'],3)\n",
    "\n",
    "def collect_rouge(model_data) :\n",
    "    return round(model_data['rouge']['rougeL'],3)\n",
    "\n",
    "def collect_bertscore(model_data) :\n",
    "    return round(np.mean(model_data['bertscore']['f1']),3)\n",
    "\n",
    "def collect_readability(model_data) :\n",
    "    scores = []\n",
    "    for k, v in model_data['readability'].items() :\n",
    "        scores.append(v['flesch_kincaid_grade'])\n",
    "    return round(np.mean(scores),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1794aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_c1_results(model_name, model_data) :\n",
    "\n",
    "    bleu = collect_bleu(model_data)\n",
    "    rouge = collect_rouge(model_data)\n",
    "    bertscore = collect_bertscore(model_data)\n",
    "    readability = collect_readability(model_data)\n",
    "\n",
    "    return {\"model\" : model_name, \"bleu\" : bleu, \"rouge\" : rouge, \"bertscore\" : bertscore, \"readability\" : readability}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a9d4150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>bleu</th>\n",
       "      <th>rouge</th>\n",
       "      <th>bertscore</th>\n",
       "      <th>readability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.853</td>\n",
       "      <td>10.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama3.2-3B</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.851</td>\n",
       "      <td>10.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama3.2-3B-sft</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.830</td>\n",
       "      <td>7.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama3.2-3B-lora</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.851</td>\n",
       "      <td>7.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama3.2-3B-lora-ppo</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.893</td>\n",
       "      <td>7.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama3.2-3B-lora-grpo</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.889</td>\n",
       "      <td>7.202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model   bleu  rouge  bertscore  readability\n",
       "0            gpt-4o-mini  0.020  0.119      0.853       10.672\n",
       "1            llama3.2-3B  0.023  0.112      0.851       10.777\n",
       "2        llama3.2-3B-sft  0.025  0.104      0.830        7.905\n",
       "3       llama3.2-3B-lora  0.031  0.125      0.851        7.636\n",
       "4   llama3.2-3B-lora-ppo  0.157  0.322      0.893        7.237\n",
       "5  llama3.2-3B-lora-grpo  0.140  0.292      0.889        7.202"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_result = []\n",
    "for model_name, result in zip(model_names, results) :\n",
    "    out = format_c1_results(model_name, result)\n",
    "    all_result.append(out)\n",
    "\n",
    "df = pd.DataFrame(all_result)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad22e93a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
