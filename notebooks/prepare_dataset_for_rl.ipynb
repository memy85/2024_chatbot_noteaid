{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00fe4fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import *\n",
    "\n",
    "config = load_config()\n",
    "PROJECT_PATH = config.project_path\n",
    "DATA_PATH = PROJECT_PATH.joinpath(\"data/raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c411e253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2422604/1835548576.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat(whole_dataset, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "whole_dataset = []\n",
    "for page in [\"page1\", \"page2\", \"page3\", \"page4\"] :\n",
    "    data = df = pd.read_excel(DATA_PATH.joinpath(\"annotation_notes.xlsx\"), sheet_name=page)\n",
    "    whole_dataset.append(data)\n",
    "\n",
    "df = pd.concat(whole_dataset, ignore_index=True)\n",
    "df.columns\n",
    "\n",
    "df = df[[\"note_id\", \"text\", \"questionnaire\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7082f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working on some filtering\n",
    "df.loc[:,\"note_id\"] = df['note_id'].str.replace(\"\\n\", \"\")\n",
    "\n",
    "example = df[\"questionnaire\"][34]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5f0e89",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# define function that parses each question and choices\n",
    "import json\n",
    "import re\n",
    "\n",
    "def parse_questions(row) :\n",
    "    questionnaire_text = row['questionnaire']\n",
    "    # preprocessing\n",
    "    questionnaire_text = questionnaire_text.strip()\n",
    "    if \"\\n\" == questionnaire_text[-2:] :\n",
    "        questionnaire_text = questionnaire_text[:-2]\n",
    "\n",
    "    question_lists = []\n",
    "    questions = questionnaire_text.split(\"|\\n\")\n",
    "    # p = re.compile();\n",
    "    for idx, q in enumerate(questions) :\n",
    "        # idx = q.index(\"?\")\n",
    "        # print(\"this is idx: \", idx)\n",
    "        question = re.findall(r\"^\\d+[\\.,\\)]\\s*(.*)\",q)[0]\n",
    "        print(question)\n",
    "        choices = re.findall(r\"([a-c])\\)\\s*(.*?)(?:\\s*\\((.*?)\\))\", q)\n",
    "        # print(choices)\n",
    "        output = {\"question\" : question, \n",
    "                  \"choices\": {choice[0]: choice[1].strip() for choice in choices}, \n",
    "                  \"answer\": list(filter(lambda x : str.lower(x[2]) == \"answer\", choices))[0][0]}\n",
    "        question_lists.append(output)\n",
    "\n",
    "    return question_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aa09da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the issue row\n",
    "for i, row in df.iterrows() : \n",
    "    try  : \n",
    "        parse_questions(row)\n",
    "    except :\n",
    "        raise RuntimeError(f\"The error is caused in : {i} / {row['note_id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609d300a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Now start parsing\n",
    "p = df.apply(parse_questions, axis=1)\n",
    "len(p[1][1]['choices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9413a7f1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# create checker \n",
    "def checker(list_of_questions) :\n",
    "    for q in list_of_questions :\n",
    "        if len(q['choices']) < 3 :\n",
    "            return True\n",
    "    return False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2af202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identity problematic rows\n",
    "for i, lq in enumerate(p) :\n",
    "    a = checker(lq)\n",
    "    if a :\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ae4af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fbdca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create shuffler\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "def shuffler(question) :\n",
    "    original_choices = ['a', 'b', 'c']\n",
    "    new_choices = ['a', 'b', 'c']\n",
    "    random.shuffle(new_choices)\n",
    "\n",
    "    choice = question['answer']\n",
    "    shuffled_choices = {}\n",
    "    for oc, nc in zip(original_choices, new_choices) :\n",
    "        shuffled_choices[oc] = question['choices'][nc]\n",
    "        if nc == choice : \n",
    "            new_answer = oc\n",
    "\n",
    "    question['choices'] = shuffled_choices\n",
    "    question['answer'] = new_answer\n",
    "    return question\n",
    "\n",
    "s = p[0][0]\n",
    "\n",
    "shuffler(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8373857",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "a = p.apply(lambda x: list(map(shuffler, x)))\n",
    "\n",
    "df['original_extracted'] = p\n",
    "df['question_rl'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fcc696",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Save the dataset\n",
    "df.to_pickle(PROJECT_PATH.joinpath('data/processed/rl_dataset.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d79652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "r = df.loc[idx, :]\n",
    "r.note_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e21b2ce",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a4dbe4",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Read pickle"
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(PROJECT_PATH.joinpath('data/processed/rl_dataset.pkl'))\n",
    "import json\n",
    "a = json.loads(df.to_json())\n",
    "a['note_id'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f30e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PROJECT_PATH.joinpath('data/processed/synthetic_notes_for_rl.pkl'), 'rb') as f :\n",
    "    rl = pickle.load(f)\n",
    "\n",
    "\n",
    "with open(PROJECT_PATH.joinpath('data/processed/synthetic_notes_for_test.pkl'), 'rb') as f :\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d26ae",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Prepare gold label dataset"
   },
   "outputs": [],
   "source": [
    "\n",
    "gold = pd.read_pickle(PROJECT_PATH.joinpath(\"data/processed/gold.pkl\"))\n",
    "gold.to_json(PROJECT_PATH.joinpath('data/processed/gold.json'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
